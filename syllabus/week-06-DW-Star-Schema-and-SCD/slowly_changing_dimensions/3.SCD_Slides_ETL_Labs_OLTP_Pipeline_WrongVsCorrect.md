# Slowly Changing Dimensions (SCD) <br>in Data Warehousing  
## Slide-ready deck + MySQL ETL + OLTP→SCD pipeline + Labs + “wrong vs correct” demos

**Audience:** Students new to SCD  
**Assumed stack:** MySQL 8.x (works with 8.0+)  
**Format:** Markdown compatible with Marp / Reveal-style separators (`---`)  

---

# How to use this file

- **Slides:** Use the sections labeled “Slide …” and the `---` separators.
- **Hands-on:** Copy/paste SQL blocks into MySQL Workbench or CLI.
- **Labs:** Each lab has **tasks** and **solutions**.

---

# Slide 1 — The core problem

* **Facts** (sales, orders, payments) are recorded at a point in time.  
* **Dimensions** (customer, product, employee) describe the context.

But context changes.

**Examples:**

- Customer moves to a new city
- Product changes category
- Employee changes department
- Customer’s loyalty tier changes

**Question:**  
When a dimension attribute changes, how do we keep analytics *historically correct*?

---

# Slide 2 — What is a Slowly Changing Dimension?

A **Slowly Changing Dimension (SCD)** is a dimension whose attributes change over time, but not as frequently as facts.

**SCD design answers:**

- Do we overwrite old values?
- Do we keep history?
- How much history do we keep?
- How do facts reference the correct version?

---

# Slide 3 — Why you should care (one sentence)

> If you handle SCD incorrectly, yesterday’s reports will change when a dimension changes tomorrow.

---

# Slide 4 — SCD types (map)

| Type | Strategy | Keeps history? | Typical use |
|---|---|---:|---|
| 0 | Fixed | No | Date, immutable codes |
| 1 | Overwrite | No | Typos, corrections |
| 2 | New row per change | Yes (full) | Address, department, tier |
| 3 | Current + previous columns | Limited | “Previous manager” |
| 4 | Current table + history table | Yes (separate) | Huge dimensions |
| 6 | Hybrid (1+2+3) | Yes | Advanced BI needs |

---

# Slide 5 — Our running scenario (realistic)

We run an **e-commerce / subscription** business.

**OLTP source** captures customer profile and orders.  
Warehouse needs:

- “Sales by customer city at the time of order”
- “Revenue by loyalty tier over time”
- “Current customer contact info should be corrected when wrong”

We will model:

- **Email** → SCD Type 1 (correction)
- **City/State** → SCD Type 2 (history required)
- **Loyalty tier** → SCD Type 6 (history + previous + current)

---

# Slide 6 — Key terms you must know

- **Natural key**: business identifier (e.g., `customer_id` from OLTP)
- **Surrogate key**: warehouse identifier (e.g., `customer_sk` in the dimension)
- **Current row**: the active version of the dimension entity
- **Effective dates**: `effective_start`, `effective_end`
- **Current flag**: `is_current = 'Y'/'N'`

---

# Slide 7 — Why surrogate keys matter (Type 2+)

If customer 101 has three addresses over time, then:

- Natural key = 101 (same)
- Surrogate key changes per version: 1001, 1055, 1120…

Facts reference the **surrogate key** so that each fact ties to the correct historical version.

---

# Slide 8 — Type 0: Fixed dimension

**Definition:** Never change after insert. Ignore updates.

Examples:

- `dim_date` (year/quarter/day-of-week are deterministic)
- Standard country codes if your organization treats them as immutable

**Why Type 0?**
- Protects truth (prevents accidental corruption)
- Simplifies ETL (no updates)

---

# Slide 9 — Type 0: mini example

If someone tries to “update” 2024-01-01’s quarter to Q2:

- This is not a business change; it’s a data error.
- We reject it at ETL validation.

---

# Slide 10 — Type 1: Overwrite (no history)

**Definition:** Update the existing row in place. Old value is lost.

Best for:

- Typos and corrections (email, phone format, name spelling)
- Attributes with no analytical “as-of” requirement

---

# Slide 11 — Type 1: Extended example (Email correction)

Before:

- `sara@gmial.com` (wrong)

After:

- `sara@gmail.com` (correct)

**Why Type 1?**
- The old value is not meaningful history; it was incorrect.

---

# Slide 12 — Type 1: danger

If you use Type 1 for **city**, then “Sales by city (2022)” will change if the customer moves in 2026.

That’s usually unacceptable for analytics.

---

# Slide 13 — Type 2: New row per change (full history)

**Definition:** When tracked attributes change:

1. Expire old row (`effective_end = yesterday`, `is_current='N'`)
2. Insert new row with new values (`effective_start = today`, `is_current='Y'`)

**Best for:**

- Address/location
- Department/job role
- Any attribute needed for “as-of” historical reporting

---

# Slide 14 — Type 2: Extended example (Customer moves multiple times)

Customer 101 timeline:
- San Jose → San Francisco → New York

Warehouse rows (simplified):

| customer_sk | customer_id | city | start | end | current |
|---:|---:|---|---|---|---|
| 1001 | 101 | San Jose | 2019-01-01 | 2021-06-30 | N |
| 1055 | 101 | San Francisco | 2021-07-01 | 2024-03-31 | N |
| 1120 | 101 | New York | 2024-04-01 | NULL | Y |

---

# Slide 15 — Why Type 2 (the “as-of” promise)

Type 2 guarantees:
> Facts reference the dimension version that was valid at the time the fact occurred.

So “orders placed while customer lived in San Jose” remain correct forever.

---

# Slide 16 — Type 3: Limited history (previous value)

**Definition:** Store current and previous values in the same row.

Example columns:

- `manager_current`
- `manager_previous`

Best when:
- You only care about the last previous value (not full timeline)

---

# Slide 17 — Type 3: Extended example (Employee manager)

Employee 501:

- previous manager: Bob
- current manager: Alice

| employee_id | manager_current | manager_previous |
|---:|---|---|
| 501 | Alice | Bob |

**Why Type 3?**
- Fast, simple, no row explosion
- But only keeps 1 level of history

---

# Slide 18 — Type 4: Separate history table

**Definition:** Keep:

- a small “current” dimension table
- a separate history table containing versions

Best when:

- Dimension is huge
- Most queries need *only* current rows
- History is needed occasionally (audits, investigations)

---

# Slide 19 — Type 4: Extended example (Product pricing)

- `dim_product_current(product_id, price, category, …)`
- `dim_product_history(product_id, price, category, effective_date, …)`

**Why Type 4?**
- Performance: current dimension stays small
- History grows without slowing day-to-day analytics

---

# Slide 20 — Type 6: Hybrid (Type 1 + Type 2 + Type 3)

Type 6 is often described as:

- **Type 2** rows for full history  
- plus a **Type 3** column for “previous”  
- plus **Type 1 overwrite** for certain “current-only” attributes

Common in mature BI systems.

---

# Slide 21 — Type 6: Extended example (Loyalty tier)

We want:

- Full tier history for trends (Type 2)
- Quick access to previous tier (Type 3)
- Correct current contact fields (Type 1)

Example columns in the Type 2 dimension:

- `tier_current`
- `tier_previous`  (previous tier)
- `email` (corrected in place across current row; often treated as Type 1)

---

# Slide 22 — Decision guide

| Business question | Best type |
|---|---|
| “Old value was wrong” | Type 1 |
| “What was it at the time?” | Type 2 |
| “Only last previous matters” | Type 3 |
| “Huge history; keep current fast” | Type 4 |
| “Need current + previous + full history” | Type 6 |
| “Never changes” | Type 0 |

---

# Slide 23 — Coming up: hands-on pipeline

We will build:

1. **OLTP schema** + sample data  
2. **Staging table** (daily extracts)  
3. **Warehouse dimension** `dim_customer` supporting SCD 1/2/6  
4. **Fact table** `fact_orders` referencing surrogate keys  
5. “Wrong vs correct” reporting demo  

---

# Part A — OLTP → Staging → DW pipeline (MySQL)

## A1) Create OLTP schema

```sql
DROP DATABASE IF EXISTS oltp_scd_demo;
CREATE DATABASE oltp_scd_demo;
USE oltp_scd_demo;

CREATE TABLE oltp_customer (
  customer_id INT PRIMARY KEY,
  full_name   VARCHAR(200) NOT NULL,
  email       VARCHAR(200) NOT NULL,
  phone       VARCHAR(40),
  city        VARCHAR(120) NOT NULL,
  state       VARCHAR(40)  NOT NULL,
  loyalty_tier VARCHAR(20) NOT NULL,   -- Bronze/Silver/Gold/Platinum
  updated_at  DATETIME NOT NULL
);

CREATE TABLE oltp_orders (
  order_id    BIGINT PRIMARY KEY,
  customer_id INT NOT NULL,
  order_ts    DATETIME NOT NULL,
  status      VARCHAR(20) NOT NULL,    -- placed/paid/shipped/cancelled
  order_amount DECIMAL(12,2) NOT NULL,
  FOREIGN KEY (customer_id) REFERENCES oltp_customer(customer_id)
);
```

## A2) Insert realistic sample data (small but meaningful)

This gives a multi-year span and includes changes for SCD testing.

```sql
-- Day 1 snapshot (initial)
INSERT INTO oltp_customer
(customer_id, full_name, email, phone, city, state, loyalty_tier, updated_at)
VALUES
(101,'Sara Kim','sara@gmial.com','408-555-1001','San Jose','CA','Silver','2023-01-15 09:10:00'),
(102,'Miguel Ortega','miguel.ortega@gmail.com','408-555-1002','Sunnyvale','CA','Bronze','2023-01-15 09:12:00'),
(103,'Priya Nair','priya.nair@gmail.com','408-555-1003','Santa Clara','CA','Gold','2023-01-15 09:20:00');

-- Orders across multiple years
INSERT INTO oltp_orders
(order_id, customer_id, order_ts, status, order_amount)
VALUES
(9000001,101,'2023-02-10 14:20:00','paid',120.50),
(9000002,101,'2023-08-05 10:05:00','shipped',80.00),
(9000003,102,'2023-11-12 09:40:00','paid',55.25),
(9000004,103,'2024-03-02 12:00:00','paid',210.10),
(9000005,101,'2024-05-18 16:30:00','paid',75.00),
(9000006,103,'2025-01-25 11:15:00','shipped',99.99);
```

## A3) Simulate real changes in OLTP (later “days”)

```sql
-- Day 2: Sara email corrected (Type 1), and city changes (Type 2)
UPDATE oltp_customer
SET email='sara@gmail.com',
    city='San Francisco',
    state='CA',
    updated_at='2024-06-01 08:00:00'
WHERE customer_id=101;

-- Day 3: Sara loyalty tier changes (Type 6: track previous + full history)
UPDATE oltp_customer
SET loyalty_tier='Gold',
    updated_at='2025-02-01 09:00:00'
WHERE customer_id=101;

-- More orders after changes
INSERT INTO oltp_orders
(order_id, customer_id, order_ts, status, order_amount)
VALUES
(9000007,101,'2024-07-04 13:00:00','paid',150.00),
(9000008,101,'2025-03-10 15:10:00','paid',60.00);
```

---

# Part B — Staging tables (daily extracts)

In practice you extract OLTP to **staging** (raw-ish, load-date tagged).  
Here we model a daily customer extract.

```sql
DROP DATABASE IF EXISTS dw_scd_demo;
CREATE DATABASE dw_scd_demo;
USE dw_scd_demo;

CREATE TABLE stg_customer_snapshot (
  snapshot_date DATE NOT NULL,
  customer_id INT NOT NULL,
  full_name   VARCHAR(200) NOT NULL,
  email       VARCHAR(200) NOT NULL,
  phone       VARCHAR(40),
  city        VARCHAR(120) NOT NULL,
  state       VARCHAR(40)  NOT NULL,
  loyalty_tier VARCHAR(20) NOT NULL,
  PRIMARY KEY (snapshot_date, customer_id)
);

CREATE TABLE stg_orders (
  order_id BIGINT PRIMARY KEY,
  customer_id INT NOT NULL,
  order_ts DATETIME NOT NULL,
  status VARCHAR(20) NOT NULL,
  order_amount DECIMAL(12,2) NOT NULL
);
```

Load staging from OLTP (conceptually; in class, run these after switching databases):

```sql
-- Assume snapshot date for a load run
SET @snap = '2025-02-02';

-- Pull customer current state into staging
INSERT INTO stg_customer_snapshot
(snapshot_date, customer_id, full_name, email, phone, city, state, loyalty_tier)
SELECT @snap, c.customer_id, c.full_name, c.email, c.phone, c.city, c.state, c.loyalty_tier
FROM oltp_scd_demo.oltp_customer c;

-- Pull orders (incremental would be better; simplified here)
INSERT IGNORE INTO stg_orders
(order_id, customer_id, order_ts, status, order_amount)
SELECT o.order_id, o.customer_id, o.order_ts, o.status, o.order_amount
FROM oltp_scd_demo.oltp_orders o;
```

---

# Part C — Warehouse schema (Dimension + Fact)

## C1) Dimension for SCD (supports Type 1, 2, 6)

We’ll store:

- Type 2 fields: `city`, `state`, `loyalty_tier` (history)
- Type 3 fields (for Type 6): `loyalty_tier_prev`
- Type 1 fields: `email`, `phone`, `full_name` (corrections)

```sql
USE dw_scd_demo;

CREATE TABLE dim_customer (
  customer_sk BIGINT AUTO_INCREMENT PRIMARY KEY,
  customer_id INT NOT NULL,                 -- natural key from OLTP

  -- Type 1 attributes (overwrite on correction)
  full_name   VARCHAR(200) NOT NULL,
  email       VARCHAR(200) NOT NULL,
  phone       VARCHAR(40),

  -- Type 2/6 tracked attributes (history)
  city        VARCHAR(120) NOT NULL,
  state       VARCHAR(40)  NOT NULL,
  loyalty_tier VARCHAR(20) NOT NULL,

  -- Type 3 component for Type 6
  loyalty_tier_prev VARCHAR(20),

  -- Type 2 metadata
  effective_start DATE NOT NULL,
  effective_end   DATE NULL,
  is_current      CHAR(1) NOT NULL DEFAULT 'Y',

  -- housekeeping
  source_snapshot_date DATE NOT NULL,

  UNIQUE KEY uk_dim_customer_current (customer_id, is_current),
  INDEX ix_dim_customer_nk (customer_id),
  INDEX ix_dim_customer_dates (effective_start, effective_end)
);

CREATE TABLE fact_orders (
  order_id BIGINT PRIMARY KEY,
  customer_sk BIGINT NOT NULL,
  order_ts DATETIME NOT NULL,
  status VARCHAR(20) NOT NULL,
  order_amount DECIMAL(12,2) NOT NULL,
  INDEX ix_fact_orders_customer_sk (customer_sk),
  CONSTRAINT fk_fact_orders_customer_sk
    FOREIGN KEY (customer_sk) REFERENCES dim_customer(customer_sk)
);
```

---

# Part D — ETL SQL for SCD Type 1, Type 2, and Type 6 (MySQL)

MySQL has no `MERGE`, so we implement SCD logic using:

- joins
- temp tables
- transactions
- UPDATE + INSERT

## D0) Helper: create a “current view” of dim_customer

```sql
CREATE OR REPLACE VIEW vw_dim_customer_current AS
SELECT *
FROM dim_customer
WHERE is_current='Y';
```

---

## D1) Type 1 ETL (overwrite corrections)

**Goal:** update Type 1 attributes in the current dimension row, without creating new history rows.

Type 1 attributes here:
- `full_name`, `email`, `phone`

```sql
START TRANSACTION;

UPDATE dim_customer d
JOIN stg_customer_snapshot s
  ON s.customer_id = d.customer_id
 AND s.snapshot_date = @snap
SET
  d.full_name = s.full_name,
  d.email     = s.email,
  d.phone     = s.phone
WHERE d.is_current='Y'
  AND (
       d.full_name <> s.full_name
    OR d.email     <> s.email
    OR IFNULL(d.phone,'') <> IFNULL(s.phone,'')
  );

COMMIT;
```

**Why this is Type 1:**  
We treat these as corrections, not meaningful historical changes.

---

## D2) Type 2 ETL (new row when tracked attributes change)

Tracked Type 2 attributes here:

- `city`, `state`  
(we’ll handle `loyalty_tier` as part of Type 6 in the next section)

**Steps:**

1) Find customers whose tracked attributes changed  
2) Expire current row  
3) Insert new row as current  

### D2.1) Identify Type 2 changes

```sql
DROP TEMPORARY TABLE IF EXISTS tmp_type2_changed;
CREATE TEMPORARY TABLE tmp_type2_changed AS
SELECT
  s.customer_id,
  s.full_name, s.email, s.phone,
  s.city, s.state, s.loyalty_tier,
  d.customer_sk AS current_customer_sk
FROM stg_customer_snapshot s
JOIN dim_customer d
  ON d.customer_id = s.customer_id
 AND d.is_current='Y'
WHERE s.snapshot_date = @snap
  AND (
       d.city  <> s.city
    OR d.state <> s.state
  );
```

### D2.2) Expire the current row

```sql
START TRANSACTION;

UPDATE dim_customer d
JOIN tmp_type2_changed c
  ON c.customer_id = d.customer_id
SET
  d.effective_end = DATE_SUB(@snap, INTERVAL 1 DAY),
  d.is_current = 'N'
WHERE d.is_current='Y';

COMMIT;
```

### D2.3) Insert the new current row

```sql
START TRANSACTION;

INSERT INTO dim_customer
(customer_id, full_name, email, phone, city, state, loyalty_tier,
 loyalty_tier_prev, effective_start, effective_end, is_current, source_snapshot_date)
SELECT
  c.customer_id,
  c.full_name, c.email, c.phone,
  c.city, c.state, c.loyalty_tier,
  NULL AS loyalty_tier_prev,
  @snap AS effective_start,
  NULL AS effective_end,
  'Y' AS is_current,
  @snap AS source_snapshot_date
FROM tmp_type2_changed c;

COMMIT;
```

**Why this is Type 2:**  
We need the *old city/state* preserved so historic “sales by city” remains correct.

---

## D3) Type 6 ETL (hybrid: Type 2 + Type 3 + Type 1)

In our model:

- `loyalty_tier` is tracked as Type 2 history  
- `loyalty_tier_prev` stores immediate prior tier (Type 3 component)  
- `email/phone/name` remain Type 1 corrections on the current row

### D3.1) Identify loyalty tier changes on current row

```sql
DROP TEMPORARY TABLE IF EXISTS tmp_tier_changed;
CREATE TEMPORARY TABLE tmp_tier_changed AS
SELECT
  s.customer_id,
  s.full_name, s.email, s.phone,
  s.city, s.state, s.loyalty_tier AS new_tier,
  d.customer_sk AS current_customer_sk,
  d.loyalty_tier AS old_tier
FROM stg_customer_snapshot s
JOIN dim_customer d
  ON d.customer_id = s.customer_id
 AND d.is_current='Y'
WHERE s.snapshot_date=@snap
  AND d.loyalty_tier <> s.loyalty_tier;
```

### D3.2) Expire current row (Type 2 part)

```sql
START TRANSACTION;

UPDATE dim_customer d
JOIN tmp_tier_changed t
  ON t.customer_id = d.customer_id
SET
  d.effective_end = DATE_SUB(@snap, INTERVAL 1 DAY),
  d.is_current='N'
WHERE d.is_current='Y';

COMMIT;
```

### D3.3) Insert new row with tier_prev filled (Type 3 part)

```sql
START TRANSACTION;

INSERT INTO dim_customer
(customer_id, full_name, email, phone, city, state, loyalty_tier,
 loyalty_tier_prev, effective_start, effective_end, is_current, source_snapshot_date)
SELECT
  t.customer_id,
  t.full_name, t.email, t.phone,
  t.city, t.state, t.new_tier,
  t.old_tier AS loyalty_tier_prev,
  @snap AS effective_start,
  NULL AS effective_end,
  'Y' AS is_current,
  @snap AS source_snapshot_date
FROM tmp_tier_changed t;

COMMIT;
```

### D3.4) Apply Type 1 corrections after Type 6 insert (optional but common)

If contact info changed too, update the current row to match staging:

```sql
START TRANSACTION;

UPDATE dim_customer d
JOIN stg_customer_snapshot s
  ON s.customer_id = d.customer_id
 AND s.snapshot_date=@snap
SET
  d.full_name = s.full_name,
  d.email     = s.email,
  d.phone     = s.phone
WHERE d.is_current='Y'
  AND (
       d.full_name <> s.full_name
    OR d.email     <> s.email
    OR IFNULL(d.phone,'') <> IFNULL(s.phone,'')
  );

COMMIT;
```

**Why this is Type 6:**  

Analysts get:

- Full tier history via Type 2 rows  
- Quick “previous tier” via `loyalty_tier_prev`  
- Corrected contact info via Type 1 overwrites  

---

## D4) Insert new customers (first time seen)

```sql
INSERT INTO dim_customer
(customer_id, full_name, email, phone, city, state, loyalty_tier,
 loyalty_tier_prev, effective_start, effective_end, is_current, source_snapshot_date)
SELECT
  s.customer_id, s.full_name, s.email, s.phone, s.city, s.state, s.loyalty_tier,
  NULL, @snap, NULL, 'Y', @snap
FROM stg_customer_snapshot s
LEFT JOIN dim_customer d
  ON d.customer_id = s.customer_id
WHERE s.snapshot_date=@snap
  AND d.customer_id IS NULL;
```

---

## D5) Load facts and resolve surrogate keys correctly

Facts must reference the correct dimension version.  
For orders, the correct version is determined by **order date** falling within effective dates.

```sql
INSERT IGNORE INTO fact_orders
(order_id, customer_sk, order_ts, status, order_amount)
SELECT
  o.order_id,
  d.customer_sk,
  o.order_ts,
  o.status,
  o.order_amount
FROM stg_orders o
JOIN dim_customer d
  ON d.customer_id = o.customer_id
 AND DATE(o.order_ts) >= d.effective_start
 AND (d.effective_end IS NULL OR DATE(o.order_ts) <= d.effective_end);
```

---

# Part E — “Wrong vs Correct” report demos (why SCD matters)

## E1) WRONG approach: Type 1 overwrite for city

If city is overwritten, all historical orders for that customer appear in the *new* city.

**Wrong query pattern:** join facts to current dimension row only:

```sql
-- WRONG: joining facts to only current dim row
SELECT
  d.city,
  COUNT(*) AS orders,
  SUM(f.order_amount) AS revenue
FROM fact_orders f
JOIN vw_dim_customer_current d
  ON d.customer_sk = f.customer_sk   -- even worse: if facts were loaded with current only
GROUP BY d.city
ORDER BY revenue DESC;
```

### Why it’s wrong
If customer moved in 2024, their 2023 orders will be “re-attributed” to 2024 city.

---

## E2) CORRECT approach: Type 2 dimension version join

Facts use the version valid at order time (via surrogate key assignment and/or date-range join).

Correct report:

```sql
SELECT
  d.city,
  COUNT(*) AS orders,
  SUM(f.order_amount) AS revenue
FROM fact_orders f
JOIN dim_customer d
  ON d.customer_sk = f.customer_sk
GROUP BY d.city
ORDER BY revenue DESC;
```

This is correct because the ETL loaded `customer_sk` corresponding to the customer version at the order date.

---

## E3) Demonstration: compare “as-of” behavior

**Question:** Revenue by city for 2023 vs 2025

```sql
-- 2023 revenue by city
SELECT d.city, SUM(f.order_amount) AS revenue_2023
FROM fact_orders f
JOIN dim_customer d ON d.customer_sk=f.customer_sk
WHERE YEAR(f.order_ts)=2023
GROUP BY d.city
ORDER BY revenue_2023 DESC;

-- 2025 revenue by city
SELECT d.city, SUM(f.order_amount) AS revenue_2025
FROM fact_orders f
JOIN dim_customer d ON d.customer_sk=f.customer_sk
WHERE YEAR(f.order_ts)=2025
GROUP BY d.city
ORDER BY revenue_2025 DESC;
```

**Expected teaching point:**  

If Sara moved from San Jose → San Francisco, you will see her 2023 revenue in San Jose (correct), not San Francisco.

---

# Part F — Lab assignments (with solutions)

## Lab 1 — Identify which attributes should be Type 1 vs Type 2 vs Type 6


### Tasks

Given these customer attributes, classify each:

- full_name
- email
- phone
- city
- state
- loyalty_tier

Explain why.

### Solution
- full_name → **Type 1** (mostly corrections; history rarely needed for analytics)
- email → **Type 1** (typo correction; old value not meaningful)
- phone → **Type 1** (format correction; old number often not analytically useful)
- city/state → **Type 2** (geo analytics must be historically correct)
- loyalty_tier → **Type 6** (full history for trends + previous tier is a useful analytic feature)

---

## Lab 2 — Implement SCD Type 1 ETL (email correction)

### Tasks
1) Load `stg_customer_snapshot` for a chosen `@snap`.  
2) Write Type 1 update to overwrite `email` when it changes.  
3) Prove it works by showing before/after for customer 101.

### Solution
Use the **D1** block and verify:

```sql
SELECT customer_id, email
FROM dim_customer
WHERE customer_id=101 AND is_current='Y';
```

---

## Lab 3 — Implement SCD Type 2 ETL (city/state history)

### Tasks
1) Create `dim_customer` if not created.  
2) Run one snapshot load.  
3) Change a customer city in OLTP, load a new snapshot.  
4) Run Type 2 ETL and show two versions in `dim_customer`.

### Solution
Run:
- D2.1, D2.2, D2.3  
Then:

```sql
SELECT customer_id, city, state, effective_start, effective_end, is_current
FROM dim_customer
WHERE customer_id=101
ORDER BY effective_start;
```

---

## Lab 4 — Implement Type 6 ETL (tier history + tier_prev)

### Tasks
1) Make a customer tier change in OLTP.  
2) Load snapshot.  
3) Run Type 6 ETL (D3.1–D3.4).  
4) Show that the new row has `loyalty_tier_prev` set.

### Solution
Verify:

```sql
SELECT customer_id, loyalty_tier, loyalty_tier_prev, effective_start, effective_end, is_current
FROM dim_customer
WHERE customer_id=101
ORDER BY effective_start;
```

Expected: latest row has `loyalty_tier_prev = 'Silver'` (or prior value).

---

## Lab 5 — “Wrong vs correct report” experiment

### Tasks
1) Produce revenue by city for 2023.  
2) Now (incorrectly) update city using Type 1 overwrite on current row.  
3) Re-run report and observe the change.  
4) Restore correct Type 2 logic and re-run to show stability.

### Solution (outline)
- Use the correct ETL pipeline (Type 2) and queries in Part E.
- The stable result demonstrates why SCD exists.

---

# Part G — Teaching extras (optional slide inserts)

## Slide — Common mistakes checklist
- Joining facts to **current** dimension row only
- Using Type 1 for attributes that drive historical analytics
- Not using surrogate keys for Type 2
- Forgetting to set `effective_end` correctly
- Not constraining “one current row per natural key”

## Slide — What students should remember
- Type 1: correct mistakes
- Type 2: preserve history
- Type 6: preserve history + previous + corrected current

---

# Appendix — Quick “run order” (for class)

1) Run **Part A** (OLTP create + seed)  
2) Run **Part B** (staging create + load snapshot)  
3) Run **Part C** (DW create)  
4) Run **D4** (new customers)  
5) Run **D1** (Type 1 corrections)  
6) Run **D2** (Type 2 changes)  
7) Run **D3** (Type 6 tier changes)  
8) Run **D5** (fact load)  
9) Run **Part E** reports  

---

End of complete SCD teaching packet.
