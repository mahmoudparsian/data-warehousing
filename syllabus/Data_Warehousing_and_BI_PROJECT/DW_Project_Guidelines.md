# Data Warehousing Project 

* Last updated date: 1/25/2026, 5:00 PM PST 

		NOTE: This is a live document 
		and will be updated on a daily basis.

* The goal of this project is to design, build, 
  and demo a data warehouse, and fianlly 
  
* Provide/show 7 OLAP queries, which will help 
  the businesses to make better decisions
  
* Based on these 7 OLAP queries: what are your 
  recommendations to the business leaders

## 1. Team 

* Each team is comprised of 2/3 students

* Each student should act as a co-leader of a team

## 2. Deadlines

| Activity                      | Must be completed by/before |
|-------------------------------|-----------------------------| 
| Team selection                | TBDL                        |
| Data selection                | TBDL                        |
| Exploratory Data Presentation | TBDL                        |
| Final Project Presentation    | TBDL                        |



## 3. Points

This project covers 40% of your overall grade.

* 10% points: Exploratory Data Presentation

* 10% points: Documentation

* 10% points: Implementation

* 10% points: Final Presentation with Powerpoint and Tableau


### 3.1 Data Exploration: 
	Data exploration also known as Exploratory Data 
	Analysis (EDA), is the crucial first step in data 
	analysis where you use visualization and statistics 
	to  understand a dataset's structure, patterns, 
	outliers, and relationships before formal modeling, 
	helping you uncover insights, identify issues, and 
	guide further analysis. It's like being a detective 
	for your  data, using  automated  tools and manual 
	checks  to get a  feel  for what's  inside,  find 
	anomalies, and determine the best path forward. 

### 3.2 Data Documentation in Data Warehousing
	Data documentation in data warehousing is the process 
	of creating a comprehensive, organized record that 
	describes the origin, structure, meaning, and intended 
	use of data within a warehouse. It serves as a roadmap 
	for users—such as data analysts, engineers, and business
	stakeholders—to understand, trust, and properly analyze 
	the information stored in the system. 
	
### 3.3 Data Implementation in Data Warehousing
	Data implementation in data warehousing means designing, 
	building, and deploying a centralized system to collect, 
	clean, integrate, and store data from various sources for 
	business analysis and reporting, using processes like ETL 
	(Extract, Transform, Load) to create a single source of 
	truth for historical data to support better decision-making. 
	It's the practical process of making a data warehouse 
	functional, from initial planning to user access. 

### 3.4 Data Presentation in Data Warehousing
	Data presentation in data warehousing refers to the 
	Presentation Layer,  the top  tier where  end-users 
	access, analyze, and visualize integrated data from 
	the warehouse using tools like dashboards (Tableau, 
	Power BI), reports, and SQL queries, transforming 
	raw data into actionable business insights. It's the 
	interface  that  makes  complex,  historical  data 
	understandable for decision-making, focusing on what 
	happened and why, unlike operational systems focused 
	on current tasks. 


## 4. Data

* your data must make sense for data warehousing
* your data must span over years (2 to 5 years) 
* with minimum of 1 to 10 million records

-------

## 5. Building Your DW Project

1. What is your DW Project? 

2. How you will build a Data Warehouse 

3. Database: MySQL or you choice (must be able to hold at least 10 millions of records per table).
	* source database and files
	* target database (where a data warehouse is built)

4.  Programming Language: Python or your choice

## 6. Project components

Components of your project should cover:

1. Project Document

2. Project Implementation

3. Presentation of your project to the whole class 

	* Presentation time: 15 to 20 minutes
	* Will be done 2 weeks before final exam


## 7. Data Set Descripton

To describe a dataset, you typically need to: 

	1. identify the source and context of the data, 

	2. list the variables and their data types, 

	3. summarize central tendencies (mean, median, mode), 

	4. analyze the distribution and spread (standard 
	   deviation, range), 

	5. identify any outliers, and visualize the data 
	   using appropriate graphs to reveal patterns 
	   and relationships; 
	   
	6. this often involves initial data cleaning 
	   and preparation 


### 7.1 Key steps in describing a dataset:

**Define the objective:**

        Clearly state the purpose of the data collection 
        and what insights you aim to extract. 

**Data collection:**

        Explain how the data was gathered, including 
        the sampling method, timeframe, and any 
        relevant demographics. 

**Data cleaning:**

        Identify and address missing values, inconsistencies, 
        outliers, and potential errors in the data. 

**Variable description:**

        List all variables: Enumerate each variable 
        included in the dataset, specifying whether 
        they are categorical or numerical. 

**Data types:**

        Define the data type for each variable (e.g., 
        integer, string, date). 

**Variable labels:**

        Clearly explain what each variable represents. 

**Descriptive statistics:**

        Central tendency: Calculate measures like mean, 
        median, and mode for each relevant variable to 
        understand the "center" of the data distribution. 

        Spread/Variability: Calculate measures like standard 
        deviation, range, and interquartile range to assess 
        how spread out the data is. 

**Data visualization:**

        Histograms: Visualize the distribution of 
        numerical variables. 

        Boxplots: Compare the distribution of a 
        variable across different groups. 

        Scatter plots: Examine relationships between 
        two numerical variables. 

        Bar charts: Visualize the frequencies of 
        categorical variables. 

**Outlier analysis:**

        Identify and discuss any extreme data points that 
        deviate significantly from the overall pattern. 

**Correlations:**

        Analyze relationships between variables using 
        correlation coefficients to understand how they 
        might be associated. 

**Interpretation:**

        Explain the key findings from your 
        descriptive analysis, highlighting 
        significant patterns, trends, and 
        potential insights. 

**Important considerations:**

         Context matters: Always consider the context of the 
         data when interpreting results. 

         Data quality: Ensure the data is accurate, complete, 
         and reliable before proceeding with analysis. 

         Audience suitability: Tailor your description to the 
         level of understanding of your audience. 


## 8. [Exploratory Data Analysis on Iris Dataset](https://www.geeksforgeeks.org/exploratory-data-analysis-on-iris-dataset/)

The Iris dataset is a well-known dataset in machine learning, 
containing measurements of sepal and petal length and width for 
three different species of Iris flowers (Setosa, Versicolor, and 
Virginica), making it a classic example for classification tasks 
due to its simplicity and clear separation between the species; 
it's often used to test and compare the performance of different 
classification algorithms as beginners learn basic machine learning 
concepts like data preprocessing and model evaluation. 

[Iris Data Set explanation](https://www.google.com/url?sa=i&url=https%3A%2F%2Feminebozkus.medium.com%2Fexploring-the-iris-flower-dataset-4e000bcc266c&psig=AOvVaw1Go-kA_gCR6iyZmW-B5vWF&ust=1737704841918000&source=images&cd=vfe&opi=89978449&ved=0CBEQjRxqFwoTCNDpw5uti4sDFQAAAAAdAAAAABAE)


## 9. Project Document Structure

1. Introduction
	* Describe your project in 5 bullet items

2. **Data:**
	* Describe your data, make sense of the data
	* Source of data, years, ...
	* Data attributes
	* What features of data are important
	* Data exploration with charts and graphs

3. ETL/ELT:  
	* Your Python/ETL/SQL scripts, what they do ...
	* Description of your scripts, what they do ...
	* ETL/ELT: how to load data to DW by year (2020, 2021, 2022, ...)

4. Star schema

	* How to build your star schema, logic and rationale 
	* Star schema description: FACT table(s) and DIM tables
	* BI queries and presentations: list of 5 queries in English and SQL
	* Tableau presentation
	* Your recommendations based on 5 OLAP queries

